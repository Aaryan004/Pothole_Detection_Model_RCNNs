{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cf8675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered Datasets:\n",
      "Metadata(name='my_train_dataset', json_file='dataset/train/annotations.json', image_root='dataset/train/images', evaluator_type='coco', thing_classes=['pothole'], thing_dataset_id_to_contiguous_id={1: 0})\n",
      "Metadata(name='my_val_dataset', json_file='dataset/val/annotations.json', image_root='dataset/val/images', evaluator_type='coco')\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/18 11:54:23 d2.config.compat]: \u001b[0mConfig 'config/pothole_detection_config.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n",
      "\u001b[32m[01/18 11:54:24 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): Res5ROIHeads(\n",
      "    (pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=2048, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/18 11:54:24 d2.data.datasets.coco]: \u001b[0mLoaded 80 images in COCO format from dataset/train/annotations.json\n",
      "\u001b[32m[01/18 11:54:24 d2.data.build]: \u001b[0mRemoved 1 images with no usable annotations. 79 images left.\n",
      "\u001b[32m[01/18 11:54:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/18 11:54:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/18 11:54:24 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/18 11:54:24 d2.data.common]: \u001b[0mSerializing 79 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/18 11:54:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
      "\u001b[32m[01/18 11:54:24 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=4\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/18 11:54:24 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[01/18 11:54:24 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from  ...\n",
      "\u001b[32m[01/18 11:54:24 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Pyton 3.11\\Lib\\site-packages\\torch\\functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4312.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/18 11:54:41 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 19  total_loss: 86.47  loss_cls: 55.12  loss_box_reg: 10.26  loss_rpn_cls: 12.12  loss_rpn_loc: 18.22    time: 0.5666  last_time: 0.6951  data_time: 0.2092  last_data_time: 0.0035   lr: 2.881e-07  max_mem: 2409M\n",
      "WARNING:tensorflow:From C:\\Pyton 3.11\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\u001b[32m[01/18 11:55:10 d2.utils.events]: \u001b[0m eta: 0:20:26  iter: 39  total_loss: 20.53  loss_cls: 11.24  loss_box_reg: 1.34  loss_rpn_cls: 3.399  loss_rpn_loc: 5.146    time: 0.6441  last_time: 0.7008  data_time: 0.0033  last_data_time: 0.0036   lr: 4.861e-07  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:55:24 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 59  total_loss: 12.9  loss_cls: 7.65  loss_box_reg: 0.6316  loss_rpn_cls: 1.397  loss_rpn_loc: 2.95    time: 0.6648  last_time: 0.7081  data_time: 0.0033  last_data_time: 0.0033   lr: 6.841e-07  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:55:39 d2.utils.events]: \u001b[0m eta: 0:20:07  iter: 79  total_loss: 10.25  loss_cls: 6.466  loss_box_reg: 0.3871  loss_rpn_cls: 1.355  loss_rpn_loc: 2.446    time: 0.6766  last_time: 0.7510  data_time: 0.0037  last_data_time: 0.0080   lr: 8.821e-07  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:55:54 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 99  total_loss: 7.312  loss_cls: 3.892  loss_box_reg: 0.3134  loss_rpn_cls: 1.017  loss_rpn_loc: 1.676    time: 0.6895  last_time: 0.7269  data_time: 0.0035  last_data_time: 0.0074   lr: 1.0801e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:56:08 d2.utils.events]: \u001b[0m eta: 0:19:46  iter: 119  total_loss: 7.073  loss_cls: 4.897  loss_box_reg: 0.6474  loss_rpn_cls: 0.8313  loss_rpn_loc: 1.706    time: 0.6951  last_time: 0.7137  data_time: 0.0036  last_data_time: 0.0031   lr: 1.2781e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:56:22 d2.utils.events]: \u001b[0m eta: 0:19:34  iter: 139  total_loss: 11.88  loss_cls: 7.012  loss_box_reg: 0.544  loss_rpn_cls: 0.8286  loss_rpn_loc: 1.775    time: 0.6974  last_time: 0.7039  data_time: 0.0037  last_data_time: 0.0038   lr: 1.4761e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:56:36 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 159  total_loss: 14.56  loss_cls: 12.72  loss_box_reg: 0.292  loss_rpn_cls: 0.782  loss_rpn_loc: 1.267    time: 0.6989  last_time: 0.7074  data_time: 0.0032  last_data_time: 0.0032   lr: 1.6741e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:56:51 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 179  total_loss: 4.287  loss_cls: 2.138  loss_box_reg: 0.1526  loss_rpn_cls: 0.6668  loss_rpn_loc: 1.145    time: 0.7003  last_time: 0.7068  data_time: 0.0034  last_data_time: 0.0033   lr: 1.8721e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:57:05 d2.utils.events]: \u001b[0m eta: 0:18:53  iter: 199  total_loss: 5.824  loss_cls: 3.371  loss_box_reg: 0.1751  loss_rpn_cls: 0.6542  loss_rpn_loc: 1.177    time: 0.7011  last_time: 0.7095  data_time: 0.0036  last_data_time: 0.0037   lr: 2.0701e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:57:19 d2.utils.events]: \u001b[0m eta: 0:18:39  iter: 219  total_loss: 3.898  loss_cls: 1.488  loss_box_reg: 0.19  loss_rpn_cls: 0.5852  loss_rpn_loc: 1.104    time: 0.7022  last_time: 0.7130  data_time: 0.0035  last_data_time: 0.0033   lr: 2.2681e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:57:33 d2.utils.events]: \u001b[0m eta: 0:18:25  iter: 239  total_loss: 2.401  loss_cls: 0.4055  loss_box_reg: 0.3874  loss_rpn_cls: 0.4995  loss_rpn_loc: 0.9539    time: 0.7034  last_time: 0.7076  data_time: 0.0036  last_data_time: 0.0030   lr: 2.4661e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:57:48 d2.utils.events]: \u001b[0m eta: 0:18:12  iter: 259  total_loss: 3.011  loss_cls: 0.6631  loss_box_reg: 0.361  loss_rpn_cls: 0.5565  loss_rpn_loc: 1.115    time: 0.7043  last_time: 0.7126  data_time: 0.0033  last_data_time: 0.0031   lr: 2.6641e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:58:02 d2.utils.events]: \u001b[0m eta: 0:17:59  iter: 279  total_loss: 4.753  loss_cls: 2.774  loss_box_reg: 0.3081  loss_rpn_cls: 0.4772  loss_rpn_loc: 0.9927    time: 0.7050  last_time: 0.7066  data_time: 0.0033  last_data_time: 0.0024   lr: 2.8621e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:58:16 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 299  total_loss: 5.69  loss_cls: 4.29  loss_box_reg: 0.269  loss_rpn_cls: 0.4426  loss_rpn_loc: 0.9587    time: 0.7059  last_time: 0.7161  data_time: 0.0034  last_data_time: 0.0033   lr: 3.0601e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:58:31 d2.utils.events]: \u001b[0m eta: 0:17:32  iter: 319  total_loss: 2.044  loss_cls: 0.588  loss_box_reg: 0.2249  loss_rpn_cls: 0.4022  loss_rpn_loc: 0.7028    time: 0.7067  last_time: 0.7259  data_time: 0.0033  last_data_time: 0.0038   lr: 3.2581e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:58:45 d2.utils.events]: \u001b[0m eta: 0:17:18  iter: 339  total_loss: 2.046  loss_cls: 0.5146  loss_box_reg: 0.2088  loss_rpn_cls: 0.4158  loss_rpn_loc: 0.7189    time: 0.7076  last_time: 0.7206  data_time: 0.0034  last_data_time: 0.0032   lr: 3.4561e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:59:00 d2.utils.events]: \u001b[0m eta: 0:17:04  iter: 359  total_loss: 1.973  loss_cls: 0.3409  loss_box_reg: 0.2583  loss_rpn_cls: 0.412  loss_rpn_loc: 0.826    time: 0.7083  last_time: 0.7289  data_time: 0.0035  last_data_time: 0.0033   lr: 3.6541e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:59:14 d2.utils.events]: \u001b[0m eta: 0:16:51  iter: 379  total_loss: 1.87  loss_cls: 0.4685  loss_box_reg: 0.2434  loss_rpn_cls: 0.3661  loss_rpn_loc: 0.6009    time: 0.7090  last_time: 0.7148  data_time: 0.0035  last_data_time: 0.0036   lr: 3.8521e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:59:29 d2.utils.events]: \u001b[0m eta: 0:16:37  iter: 399  total_loss: 4.508  loss_cls: 2.611  loss_box_reg: 0.3051  loss_rpn_cls: 0.4281  loss_rpn_loc: 0.9127    time: 0.7098  last_time: 0.7205  data_time: 0.0035  last_data_time: 0.0030   lr: 4.0501e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:59:43 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 419  total_loss: 3.818  loss_cls: 2.394  loss_box_reg: 0.371  loss_rpn_cls: 0.3746  loss_rpn_loc: 0.6318    time: 0.7107  last_time: 0.7283  data_time: 0.0035  last_data_time: 0.0029   lr: 4.2481e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 11:59:58 d2.utils.events]: \u001b[0m eta: 0:16:11  iter: 439  total_loss: 3.337  loss_cls: 2.468  loss_box_reg: 0.3023  loss_rpn_cls: 0.3962  loss_rpn_loc: 0.7386    time: 0.7114  last_time: 0.7220  data_time: 0.0034  last_data_time: 0.0031   lr: 4.4461e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:00:12 d2.utils.events]: \u001b[0m eta: 0:15:57  iter: 459  total_loss: 1.927  loss_cls: 0.436  loss_box_reg: 0.3071  loss_rpn_cls: 0.403  loss_rpn_loc: 0.7159    time: 0.7122  last_time: 0.7296  data_time: 0.0032  last_data_time: 0.0029   lr: 4.6441e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:00:27 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 479  total_loss: 1.448  loss_cls: 0.302  loss_box_reg: 0.2302  loss_rpn_cls: 0.334  loss_rpn_loc: 0.5081    time: 0.7129  last_time: 0.7443  data_time: 0.0036  last_data_time: 0.0035   lr: 4.8421e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:00:41 d2.utils.events]: \u001b[0m eta: 0:15:30  iter: 499  total_loss: 1.45  loss_cls: 0.2636  loss_box_reg: 0.266  loss_rpn_cls: 0.3172  loss_rpn_loc: 0.5511    time: 0.7136  last_time: 0.7293  data_time: 0.0033  last_data_time: 0.0024   lr: 5.0401e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:00:56 d2.utils.events]: \u001b[0m eta: 0:15:17  iter: 519  total_loss: 1.931  loss_cls: 0.1899  loss_box_reg: 0.5453  loss_rpn_cls: 0.3351  loss_rpn_loc: 0.5982    time: 0.7142  last_time: 0.7238  data_time: 0.0031  last_data_time: 0.0026   lr: 5.2381e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:01:11 d2.utils.events]: \u001b[0m eta: 0:15:04  iter: 539  total_loss: 1.151  loss_cls: 0.2502  loss_box_reg: 0.2865  loss_rpn_cls: 0.2697  loss_rpn_loc: 0.4581    time: 0.7148  last_time: 0.7263  data_time: 0.0035  last_data_time: 0.0039   lr: 5.4361e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:01:25 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 559  total_loss: 1.768  loss_cls: 0.4154  loss_box_reg: 0.2434  loss_rpn_cls: 0.3191  loss_rpn_loc: 0.5681    time: 0.7154  last_time: 0.7270  data_time: 0.0033  last_data_time: 0.0032   lr: 5.6341e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:01:40 d2.utils.events]: \u001b[0m eta: 0:14:37  iter: 579  total_loss: 1.227  loss_cls: 0.1622  loss_box_reg: 0.2951  loss_rpn_cls: 0.2693  loss_rpn_loc: 0.4875    time: 0.7159  last_time: 0.7300  data_time: 0.0031  last_data_time: 0.0024   lr: 5.8321e-06  max_mem: 2409M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/18 12:01:55 d2.utils.events]: \u001b[0m eta: 0:14:24  iter: 599  total_loss: 1.952  loss_cls: 0.2933  loss_box_reg: 0.4659  loss_rpn_cls: 0.3032  loss_rpn_loc: 0.5419    time: 0.7163  last_time: 0.7240  data_time: 0.0036  last_data_time: 0.0033   lr: 6.0301e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:02:09 d2.utils.events]: \u001b[0m eta: 0:14:10  iter: 619  total_loss: 1.485  loss_cls: 0.4414  loss_box_reg: 0.3399  loss_rpn_cls: 0.2948  loss_rpn_loc: 0.479    time: 0.7168  last_time: 0.7251  data_time: 0.0033  last_data_time: 0.0072   lr: 6.2281e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:02:24 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 639  total_loss: 1.273  loss_cls: 0.3103  loss_box_reg: 0.2652  loss_rpn_cls: 0.2755  loss_rpn_loc: 0.3933    time: 0.7173  last_time: 0.7286  data_time: 0.0034  last_data_time: 0.0032   lr: 6.4261e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:02:39 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 659  total_loss: 1.799  loss_cls: 0.4556  loss_box_reg: 0.3472  loss_rpn_cls: 0.3007  loss_rpn_loc: 0.686    time: 0.7178  last_time: 0.7339  data_time: 0.0034  last_data_time: 0.0031   lr: 6.6241e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:02:53 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 679  total_loss: 1.61  loss_cls: 0.5906  loss_box_reg: 0.3498  loss_rpn_cls: 0.2214  loss_rpn_loc: 0.3998    time: 0.7183  last_time: 0.7429  data_time: 0.0033  last_data_time: 0.0037   lr: 6.8221e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:03:08 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 699  total_loss: 1.551  loss_cls: 0.4656  loss_box_reg: 0.3486  loss_rpn_cls: 0.2885  loss_rpn_loc: 0.3719    time: 0.7187  last_time: 0.7306  data_time: 0.0031  last_data_time: 0.0052   lr: 7.0201e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:03:23 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 719  total_loss: 1.55  loss_cls: 0.2782  loss_box_reg: 0.4526  loss_rpn_cls: 0.2686  loss_rpn_loc: 0.4664    time: 0.7190  last_time: 0.7230  data_time: 0.0035  last_data_time: 0.0035   lr: 7.2181e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:03:37 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 739  total_loss: 1.027  loss_cls: 0.162  loss_box_reg: 0.3234  loss_rpn_cls: 0.2361  loss_rpn_loc: 0.3069    time: 0.7195  last_time: 0.7244  data_time: 0.0036  last_data_time: 0.0048   lr: 7.4161e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:03:52 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 759  total_loss: 1.382  loss_cls: 0.1628  loss_box_reg: 0.4054  loss_rpn_cls: 0.3149  loss_rpn_loc: 0.5663    time: 0.7202  last_time: 0.7370  data_time: 0.0039  last_data_time: 0.0034   lr: 7.6141e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:04:07 d2.utils.events]: \u001b[0m eta: 0:12:18  iter: 779  total_loss: 1.486  loss_cls: 0.2663  loss_box_reg: 0.4498  loss_rpn_cls: 0.2486  loss_rpn_loc: 0.4319    time: 0.7207  last_time: 0.7464  data_time: 0.0034  last_data_time: 0.0038   lr: 7.8121e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:04:22 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 799  total_loss: 1.379  loss_cls: 0.2033  loss_box_reg: 0.3712  loss_rpn_cls: 0.3181  loss_rpn_loc: 0.4336    time: 0.7211  last_time: 0.7297  data_time: 0.0040  last_data_time: 0.0030   lr: 8.0101e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:04:36 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 819  total_loss: 1.148  loss_cls: 0.2361  loss_box_reg: 0.3372  loss_rpn_cls: 0.2531  loss_rpn_loc: 0.3746    time: 0.7215  last_time: 0.7395  data_time: 0.0038  last_data_time: 0.0038   lr: 8.2081e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:04:51 d2.utils.events]: \u001b[0m eta: 0:11:35  iter: 839  total_loss: 1.399  loss_cls: 0.2227  loss_box_reg: 0.3824  loss_rpn_cls: 0.2521  loss_rpn_loc: 0.3882    time: 0.7218  last_time: 0.7355  data_time: 0.0037  last_data_time: 0.0031   lr: 8.4061e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:05:06 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 859  total_loss: 1.175  loss_cls: 0.2017  loss_box_reg: 0.2982  loss_rpn_cls: 0.2182  loss_rpn_loc: 0.3569    time: 0.7221  last_time: 0.7339  data_time: 0.0036  last_data_time: 0.0034   lr: 8.6041e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:05:21 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 879  total_loss: 1.278  loss_cls: 0.269  loss_box_reg: 0.3746  loss_rpn_cls: 0.2485  loss_rpn_loc: 0.3932    time: 0.7225  last_time: 0.7297  data_time: 0.0034  last_data_time: 0.0029   lr: 8.8021e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:05:35 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 899  total_loss: 1.295  loss_cls: 0.3115  loss_box_reg: 0.3302  loss_rpn_cls: 0.1985  loss_rpn_loc: 0.3615    time: 0.7227  last_time: 0.7342  data_time: 0.0033  last_data_time: 0.0031   lr: 9.0001e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:05:50 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 919  total_loss: 1.387  loss_cls: 0.2479  loss_box_reg: 0.4215  loss_rpn_cls: 0.2345  loss_rpn_loc: 0.3922    time: 0.7229  last_time: 0.7198  data_time: 0.0033  last_data_time: 0.0034   lr: 9.1981e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:06:05 d2.utils.events]: \u001b[0m eta: 0:10:24  iter: 939  total_loss: 2.641  loss_cls: 1.584  loss_box_reg: 0.4093  loss_rpn_cls: 0.2329  loss_rpn_loc: 0.3997    time: 0.7231  last_time: 0.7260  data_time: 0.0032  last_data_time: 0.0031   lr: 9.3961e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:06:19 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 959  total_loss: 1.566  loss_cls: 0.8272  loss_box_reg: 0.337  loss_rpn_cls: 0.2346  loss_rpn_loc: 0.2611    time: 0.7233  last_time: 0.7326  data_time: 0.0033  last_data_time: 0.0029   lr: 9.5941e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:06:34 d2.utils.events]: \u001b[0m eta: 0:09:55  iter: 979  total_loss: 1.386  loss_cls: 0.3685  loss_box_reg: 0.5076  loss_rpn_cls: 0.2277  loss_rpn_loc: 0.3506    time: 0.7235  last_time: 0.7357  data_time: 0.0035  last_data_time: 0.0067   lr: 9.7921e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:06:49 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 999  total_loss: 1.201  loss_cls: 0.2001  loss_box_reg: 0.4072  loss_rpn_cls: 0.2778  loss_rpn_loc: 0.3362    time: 0.7236  last_time: 0.7484  data_time: 0.0032  last_data_time: 0.0029   lr: 9.9901e-06  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:07:03 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 1019  total_loss: 1.089  loss_cls: 0.209  loss_box_reg: 0.3699  loss_rpn_cls: 0.1969  loss_rpn_loc: 0.2549    time: 0.7239  last_time: 0.7300  data_time: 0.0034  last_data_time: 0.0023   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:07:18 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 1039  total_loss: 1.344  loss_cls: 0.2049  loss_box_reg: 0.4559  loss_rpn_cls: 0.2106  loss_rpn_loc: 0.2922    time: 0.7240  last_time: 0.7227  data_time: 0.0031  last_data_time: 0.0031   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:07:33 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 1059  total_loss: 1.033  loss_cls: 0.2065  loss_box_reg: 0.3738  loss_rpn_cls: 0.206  loss_rpn_loc: 0.2612    time: 0.7241  last_time: 0.7286  data_time: 0.0033  last_data_time: 0.0032   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:07:47 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 1079  total_loss: 1.416  loss_cls: 0.3199  loss_box_reg: 0.43  loss_rpn_cls: 0.2508  loss_rpn_loc: 0.3713    time: 0.7243  last_time: 0.7214  data_time: 0.0032  last_data_time: 0.0028   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:08:02 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 1099  total_loss: 1.725  loss_cls: 0.8643  loss_box_reg: 0.3557  loss_rpn_cls: 0.1908  loss_rpn_loc: 0.2511    time: 0.7244  last_time: 0.7304  data_time: 0.0036  last_data_time: 0.0048   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:08:17 d2.utils.events]: \u001b[0m eta: 0:08:15  iter: 1119  total_loss: 1.366  loss_cls: 0.3587  loss_box_reg: 0.4809  loss_rpn_cls: 0.2195  loss_rpn_loc: 0.3152    time: 0.7246  last_time: 0.7381  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:08:31 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 1139  total_loss: 1.153  loss_cls: 0.2544  loss_box_reg: 0.5093  loss_rpn_cls: 0.1718  loss_rpn_loc: 0.2551    time: 0.7247  last_time: 0.7353  data_time: 0.0035  last_data_time: 0.0034   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:08:46 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 1159  total_loss: 1.668  loss_cls: 0.4273  loss_box_reg: 0.5293  loss_rpn_cls: 0.2388  loss_rpn_loc: 0.3961    time: 0.7249  last_time: 0.7340  data_time: 0.0034  last_data_time: 0.0033   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:09:00 d2.utils.events]: \u001b[0m eta: 0:07:32  iter: 1179  total_loss: 1.334  loss_cls: 0.3224  loss_box_reg: 0.3905  loss_rpn_cls: 0.1971  loss_rpn_loc: 0.2326    time: 0.7250  last_time: 0.7333  data_time: 0.0032  last_data_time: 0.0037   lr: 1e-05  max_mem: 2409M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/18 12:09:15 d2.utils.events]: \u001b[0m eta: 0:07:17  iter: 1199  total_loss: 1.088  loss_cls: 0.2575  loss_box_reg: 0.3777  loss_rpn_cls: 0.2053  loss_rpn_loc: 0.2448    time: 0.7252  last_time: 0.7351  data_time: 0.0036  last_data_time: 0.0039   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:09:30 d2.utils.events]: \u001b[0m eta: 0:07:03  iter: 1219  total_loss: 0.9042  loss_cls: 0.1732  loss_box_reg: 0.3464  loss_rpn_cls: 0.1952  loss_rpn_loc: 0.2144    time: 0.7253  last_time: 0.7293  data_time: 0.0035  last_data_time: 0.0034   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:09:45 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 1239  total_loss: 1.416  loss_cls: 0.2223  loss_box_reg: 0.4248  loss_rpn_cls: 0.2631  loss_rpn_loc: 0.4314    time: 0.7256  last_time: 0.7354  data_time: 0.0032  last_data_time: 0.0033   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:10:00 d2.utils.events]: \u001b[0m eta: 0:06:34  iter: 1259  total_loss: 1.157  loss_cls: 0.1866  loss_box_reg: 0.4705  loss_rpn_cls: 0.1873  loss_rpn_loc: 0.2581    time: 0.7258  last_time: 0.7391  data_time: 0.0031  last_data_time: 0.0037   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:10:14 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 1279  total_loss: 1.216  loss_cls: 0.2256  loss_box_reg: 0.4606  loss_rpn_cls: 0.2105  loss_rpn_loc: 0.3074    time: 0.7260  last_time: 0.7300  data_time: 0.0037  last_data_time: 0.0040   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:10:29 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 1299  total_loss: 1.077  loss_cls: 0.171  loss_box_reg: 0.4296  loss_rpn_cls: 0.2104  loss_rpn_loc: 0.2442    time: 0.7262  last_time: 0.7288  data_time: 0.0031  last_data_time: 0.0028   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:10:44 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 1319  total_loss: 1.129  loss_cls: 0.1686  loss_box_reg: 0.4451  loss_rpn_cls: 0.1788  loss_rpn_loc: 0.283    time: 0.7264  last_time: 0.7423  data_time: 0.0034  last_data_time: 0.0035   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:10:59 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 1339  total_loss: 1.164  loss_cls: 0.1755  loss_box_reg: 0.4796  loss_rpn_cls: 0.2038  loss_rpn_loc: 0.2804    time: 0.7265  last_time: 0.7362  data_time: 0.0033  last_data_time: 0.0033   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:11:13 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 1359  total_loss: 1.097  loss_cls: 0.2254  loss_box_reg: 0.4621  loss_rpn_cls: 0.1941  loss_rpn_loc: 0.2153    time: 0.7267  last_time: 0.7608  data_time: 0.0038  last_data_time: 0.0024   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:11:28 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 1379  total_loss: 1.133  loss_cls: 0.2233  loss_box_reg: 0.4336  loss_rpn_cls: 0.2023  loss_rpn_loc: 0.2344    time: 0.7269  last_time: 0.7301  data_time: 0.0034  last_data_time: 0.0026   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:11:43 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 1399  total_loss: 1.182  loss_cls: 0.202  loss_box_reg: 0.5254  loss_rpn_cls: 0.2068  loss_rpn_loc: 0.2072    time: 0.7270  last_time: 0.7468  data_time: 0.0034  last_data_time: 0.0037   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:11:58 d2.utils.events]: \u001b[0m eta: 0:04:38  iter: 1419  total_loss: 1.368  loss_cls: 0.2986  loss_box_reg: 0.4916  loss_rpn_cls: 0.2075  loss_rpn_loc: 0.2363    time: 0.7271  last_time: 0.7310  data_time: 0.0036  last_data_time: 0.0032   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:12:12 d2.utils.events]: \u001b[0m eta: 0:04:23  iter: 1439  total_loss: 1.168  loss_cls: 0.3039  loss_box_reg: 0.5149  loss_rpn_cls: 0.1574  loss_rpn_loc: 0.206    time: 0.7273  last_time: 0.7351  data_time: 0.0031  last_data_time: 0.0032   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:12:27 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 1459  total_loss: 1.263  loss_cls: 0.3263  loss_box_reg: 0.4727  loss_rpn_cls: 0.2216  loss_rpn_loc: 0.2403    time: 0.7274  last_time: 0.7543  data_time: 0.0035  last_data_time: 0.0025   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:12:42 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 1479  total_loss: 1.083  loss_cls: 0.2203  loss_box_reg: 0.425  loss_rpn_cls: 0.1943  loss_rpn_loc: 0.2303    time: 0.7276  last_time: 0.7362  data_time: 0.0036  last_data_time: 0.0078   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:12:57 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 1499  total_loss: 0.9623  loss_cls: 0.2236  loss_box_reg: 0.4157  loss_rpn_cls: 0.1777  loss_rpn_loc: 0.1545    time: 0.7277  last_time: 0.7450  data_time: 0.0036  last_data_time: 0.0024   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:13:12 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 1519  total_loss: 1.102  loss_cls: 0.1732  loss_box_reg: 0.468  loss_rpn_cls: 0.1719  loss_rpn_loc: 0.2108    time: 0.7279  last_time: 0.7263  data_time: 0.0033  last_data_time: 0.0031   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:13:26 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 1539  total_loss: 1.35  loss_cls: 0.1981  loss_box_reg: 0.6046  loss_rpn_cls: 0.2145  loss_rpn_loc: 0.2531    time: 0.7280  last_time: 0.7463  data_time: 0.0034  last_data_time: 0.0032   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:13:41 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 1559  total_loss: 1.04  loss_cls: 0.1956  loss_box_reg: 0.5388  loss_rpn_cls: 0.1756  loss_rpn_loc: 0.1708    time: 0.7282  last_time: 0.7406  data_time: 0.0033  last_data_time: 0.0032   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:13:56 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 1579  total_loss: 1.105  loss_cls: 0.1802  loss_box_reg: 0.4689  loss_rpn_cls: 0.1834  loss_rpn_loc: 0.2279    time: 0.7283  last_time: 0.7354  data_time: 0.0036  last_data_time: 0.0032   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:14:11 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 1599  total_loss: 1.044  loss_cls: 0.1725  loss_box_reg: 0.5284  loss_rpn_cls: 0.1738  loss_rpn_loc: 0.2047    time: 0.7283  last_time: 0.7286  data_time: 0.0035  last_data_time: 0.0038   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:14:25 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 1619  total_loss: 1.156  loss_cls: 0.2935  loss_box_reg: 0.5013  loss_rpn_cls: 0.1881  loss_rpn_loc: 0.1598    time: 0.7284  last_time: 0.7340  data_time: 0.0035  last_data_time: 0.0033   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:14:40 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 1639  total_loss: 1.19  loss_cls: 0.2163  loss_box_reg: 0.5199  loss_rpn_cls: 0.1688  loss_rpn_loc: 0.2053    time: 0.7284  last_time: 0.7212  data_time: 0.0033  last_data_time: 0.0025   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:14:54 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 1659  total_loss: 1.214  loss_cls: 0.2402  loss_box_reg: 0.5154  loss_rpn_cls: 0.1921  loss_rpn_loc: 0.1932    time: 0.7285  last_time: 0.7294  data_time: 0.0040  last_data_time: 0.0033   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:15:09 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 1679  total_loss: 1.111  loss_cls: 0.2109  loss_box_reg: 0.4261  loss_rpn_cls: 0.1823  loss_rpn_loc: 0.2117    time: 0.7285  last_time: 0.7343  data_time: 0.0033  last_data_time: 0.0034   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:15:24 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 1699  total_loss: 1.093  loss_cls: 0.2118  loss_box_reg: 0.4756  loss_rpn_cls: 0.174  loss_rpn_loc: 0.1817    time: 0.7287  last_time: 0.7413  data_time: 0.0034  last_data_time: 0.0025   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:15:39 d2.utils.events]: \u001b[0m eta: 0:00:58  iter: 1719  total_loss: 1.184  loss_cls: 0.2261  loss_box_reg: 0.4723  loss_rpn_cls: 0.1881  loss_rpn_loc: 0.1883    time: 0.7288  last_time: 0.7303  data_time: 0.0032  last_data_time: 0.0026   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:15:54 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 1739  total_loss: 1.239  loss_cls: 0.1808  loss_box_reg: 0.5995  loss_rpn_cls: 0.1756  loss_rpn_loc: 0.2317    time: 0.7289  last_time: 0.7344  data_time: 0.0034  last_data_time: 0.0035   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:16:08 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 1759  total_loss: 1.118  loss_cls: 0.1915  loss_box_reg: 0.5366  loss_rpn_cls: 0.1818  loss_rpn_loc: 0.1816    time: 0.7291  last_time: 0.7403  data_time: 0.0038  last_data_time: 0.0033   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:16:23 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 1779  total_loss: 1.112  loss_cls: 0.2612  loss_box_reg: 0.5096  loss_rpn_cls: 0.1639  loss_rpn_loc: 0.1384    time: 0.7292  last_time: 0.7499  data_time: 0.0033  last_data_time: 0.0027   lr: 1e-05  max_mem: 2409M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/18 12:16:38 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1799  total_loss: 1.174  loss_cls: 0.1911  loss_box_reg: 0.4861  loss_rpn_cls: 0.1945  loss_rpn_loc: 0.209    time: 0.7293  last_time: 0.7275  data_time: 0.0034  last_data_time: 0.0027   lr: 1e-05  max_mem: 2409M\n",
      "\u001b[32m[01/18 12:16:38 d2.engine.hooks]: \u001b[0mOverall training speed: 1798 iterations in 0:21:51 (0.7293 s / it)\n",
      "\u001b[32m[01/18 12:16:38 d2.engine.hooks]: \u001b[0mTotal training time: 0:22:08 (0:00:16 on hooks)\n",
      "\u001b[32m[01/18 12:16:38 d2.data.datasets.coco]: \u001b[0mLoaded 5 images in COCO format from dataset/val/annotations.json\n",
      "\u001b[32m[01/18 12:16:38 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  pothole   | 5            |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[01/18 12:16:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/18 12:16:38 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/18 12:16:38 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/18 12:16:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/18 12:16:38 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "import detectron2\n",
    "import torch\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "import os\n",
    "\n",
    "# Setup logger for better visibility\n",
    "setup_logger()\n",
    "\n",
    "# Step 1: Register the Dataset (COCO Format)\n",
    "def register_datasets():\n",
    "    # Replace these paths with your dataset paths\n",
    "    train_json = \"dataset/train/annotations.json\"\n",
    "    train_images = \"dataset/train/images\"\n",
    "    val_json = \"dataset/val/annotations.json\"\n",
    "    val_images = \"dataset/val/images\"\n",
    "\n",
    "    register_coco_instances(\"my_train_dataset\", {}, train_json, train_images)\n",
    "    register_coco_instances(\"my_val_dataset\", {}, val_json, val_images)\n",
    "\n",
    "    # Print metadata for debugging\n",
    "    print(\"Registered Datasets:\")\n",
    "    print(MetadataCatalog.get(\"my_train_dataset\"))\n",
    "    print(MetadataCatalog.get(\"my_val_dataset\"))\n",
    "\n",
    "# Step 2: Define the Training Function\n",
    "def train_model():\n",
    "    cfg = get_cfg()\n",
    "    \n",
    "    # Load a pre-defined configuration file\n",
    "    cfg.merge_from_file(\"config/pothole_detection_config.yaml\")\n",
    "\n",
    "    # Step 3: Dataset configuration\n",
    "    cfg.DATASETS.TRAIN = (\"my_train_dataset\",)\n",
    "    cfg.DATASETS.TEST = (\"my_val_dataset\",)\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "    # Step 4: Training parameters\n",
    "    #cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849600/model_final_280758.pkl\"\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "    cfg.SOLVER.BASE_LR = 0.0001\n",
    "    cfg.SOLVER.MAX_ITER = 1800  # Adjust for quick tests\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "    \n",
    "    cfg.SOLVER.STEPS = (1000, 2000)\n",
    "    cfg.SOLVER.GAMMA = 0.1\n",
    "\n",
    "    # Enable gradient clipping\n",
    "    cfg.SOLVER.CLIP_GRADIENTS.ENABLE = True\n",
    "    cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE = \"value\"\n",
    "    cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0\n",
    "    \n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Set according to your dataset\n",
    "\n",
    "    # Step 5: Output Directory\n",
    "    cfg.OUTPUT_DIR = \"./output\"\n",
    "\n",
    "    # Step 6: Force CPU usage\n",
    "    cfg.MODEL.DEVICE = \"cuda\"\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Step 7: Initialize the Trainer\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "\n",
    "    # Resume training from a checkpoint if available\n",
    "    trainer.resume_or_load(resume=False)\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Register datasets\n",
    "    register_datasets()\n",
    "\n",
    "    # Step 2: Train the model\n",
    "    train_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44584c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
